{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Dimensionalty Reduction \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "-Machine Learning problems invlove thousands or even millions of features. \n",
    "\n",
    "-This makes the model really slow\n",
    "\n",
    "-Sometimes, it's harder' to find good solutions \n",
    "\n",
    "-Dimensionalty Reduction is a way to reduce these features into a few features without loosing information\n",
    "\n",
    "-Two Methods\n",
    "\n",
    "   Feature Selection\n",
    "    \n",
    "      1. Univariate Selection\n",
    "      2. Recursive Feature Elimination\n",
    "      3. Feature Importance\n",
    "      4. Forward Selection(Not in sklearn)\n",
    "      5. Backward Regression(Not in Sklearn)\n",
    "      6.LASSO Regression\n",
    "      7.Adaptive LASSO Regression\n",
    "   Feature Extraction\n",
    "    \n",
    "      1. Principal Component Analysis\n",
    "      2.Linear Discriminant Analysis\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Selection\n",
    "\n",
    "-Involves using statistical test to select features that have the strongest relationship with the output variable/target.\n",
    "\n",
    "-Sklearn has SelectKBest that can be used with  statistical tests to select features.\n",
    "\n",
    "-We use chisquare in the example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "SelectKBest(k=4, score_func=<function chi2 at 0x0000024BDC3FE598>)\n",
      "[  111.51969064  1411.88704064    17.60537322    53.10803984  2175.56527292\n",
      "   127.66934333     5.39268155   181.30368904]\n",
      "[[ 148.     0.    33.6   50. ]\n",
      " [  85.     0.    26.6   31. ]\n",
      " [ 183.     0.    23.3   32. ]\n",
      " [  89.    94.    28.1   21. ]\n",
      " [ 137.   168.    43.1   33. ]]\n"
     ]
    }
   ],
   "source": [
    "# Univariate Selection using sklearn\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='C:\\\\Users\\\\akoguab\\\\Desktop\\\\R and D\\\\Data science\\\\data set\\\\pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "# Feature Selection\n",
    "\n",
    "test= SelectKBest(score_func=chi2,k=4)\n",
    "\n",
    "#print(test)\n",
    "fit=test.fit(X,Y)\n",
    "\n",
    "print(fit.scores_)\n",
    "\n",
    "features=fit.transform(X)\n",
    "print(features[0:5,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-The highest scores are plas, test, mass, age\n",
    "\n",
    "-The features from the 4 chosen features are shown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Extraction(RFE)\n",
    "\n",
    "-Works by Recursively removing atrributes and builds a models on the remaining atrributes\n",
    "\n",
    "-It uses the model accuracy to identify which atrributes ( and combination of atrributes) contributes the most to predicting the target value.\n",
    "\n",
    "-The example below use Logistic Regression and RFE to select top 3 features(preg,mass,pedi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "Number of features :  3\n",
      "Selected Features [ True False False False False  True  True False]\n",
      "Ranking of Features [1 2 3 5 6 1 1 4]\n"
     ]
    }
   ],
   "source": [
    "# RFE\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='C:\\\\Users\\\\akoguab\\\\Desktop\\\\R and D\\\\Data science\\\\data set\\\\pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "rfe=RFE(model,3)\n",
    "\n",
    "fit=rfe.fit(X,Y)\n",
    "\n",
    "print(\"Number of features : \",fit.n_features_)\n",
    "\n",
    "print(\"Selected Features\", fit.support_)\n",
    "\n",
    "print(\"Ranking of Features\", fit.ranking_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance\n",
    "\n",
    "-Bagged Decison Trees like Random Forest and Extra Trees can be used to estimate the importance of features\n",
    "\n",
    "-Example below using Extra Classifier and Random Forest has Plas, age and mass as the 3 most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "Model Importance using Extra Classifier [ 0.11150512  0.23811367  0.09782034  0.0729453   0.07671828  0.16019532\n",
      "  0.11641519  0.12628678]\n",
      "Model Importance using Random Forest [ 0.08482089  0.25098323  0.09737423  0.06194788  0.08471497  0.14844741\n",
      "  0.13418332  0.13752806]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='C:\\\\Users\\\\akoguab\\\\Desktop\\\\R and D\\\\Data science\\\\data set\\\\pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "\n",
    "\n",
    "model=ExtraTreesClassifier()\n",
    "model.fit(X,Y)\n",
    "\n",
    "# Print Feature Importance with Extra Tree Classifier\n",
    "\n",
    "print(\"Model Importance using Extra Classifier\",model.feature_importances_)\n",
    "\n",
    "\n",
    "#Feature Importance with Random Forest Classifier\n",
    "\n",
    "\n",
    "model2=RandomForestClassifier()\n",
    "model2.fit(X,Y)\n",
    "\n",
    "# Print Feature Importance\n",
    "\n",
    "print(\"Model Importance using Random Forest\",model2.feature_importances_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "-Most Popular dimenstionalty reduction algorithm\n",
    "\n",
    "-Suppose you are interested in using linear models to determine relationship between a set of features/predictors and a response variable\n",
    "\n",
    "-If there is collinearity amongst your predictor variables\n",
    "\n",
    "-Collinearity amongst your variables might cause unstable models\n",
    "\n",
    "-PCA is a variable reduction strategy\n",
    "\n",
    "-In PCA, we create a weighted linear combinations of variables while retaining most of the variability in the data\n",
    "\n",
    "-Lead to fewer variables with little or no lost information\n",
    "\n",
    "-PCA retains most of the information in a high dimenstion data by transforming the data\n",
    "\n",
    "-Most of the variability in the origianl data can be retained.\n",
    "\n",
    "-Components might not be directly interpretable.\n",
    "\n",
    "-Resulting component scores can be used as input to subsequent analysis\n",
    "\n",
    "-New variables are un-correlated\n",
    "\n",
    "-Performs Eigen value decomposition of the correlation or covariance matrix\n",
    "\n",
    "-It creates components that consolidate more of the explained variance into the first few PCs.\n",
    "\n",
    "-PCs are mutually orthogonal and independent\n",
    "\n",
    "-Generated so that the first PCs accounts for most of the variation in the data followed by the second PC and so on.\n",
    "\n",
    "\n",
    "-Principal components provides least square estimates of the form Y=XB\n",
    "\n",
    "-Y is n by p component of scores\n",
    "\n",
    "-X is n by j matrix of observed variables\n",
    "\n",
    "-B is j by p matrix of eigen vectors of the correlation or covariance matrix of variables\n",
    "\n",
    "-A scree plot of eigen values can be used to decide how many components to retain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    preg  plas  pres  skin  test  mass   pedi  age  class\n",
      "0      6   148    72    35     0  33.6  0.627   50      1\n",
      "1      1    85    66    29     0  26.6  0.351   31      0\n",
      "2      8   183    64     0     0  23.3  0.672   32      1\n",
      "3      1    89    66    23    94  28.1  0.167   21      0\n",
      "4      0   137    40    35   168  43.1  2.288   33      1\n",
      "5      5   116    74     0     0  25.6  0.201   30      0\n",
      "6      3    78    50    32    88  31.0  0.248   26      1\n",
      "7     10   115     0     0     0  35.3  0.134   29      0\n",
      "8      2   197    70    45   543  30.5  0.158   53      1\n",
      "9      8   125    96     0     0   0.0  0.232   54      1\n",
      "10     4   110    92     0     0  37.6  0.191   30      0\n",
      "11    10   168    74     0     0  38.0  0.537   34      1\n",
      "12    10   139    80     0     0  27.1  1.441   57      0\n",
      "13     1   189    60    23   846  30.1  0.398   59      1\n",
      "14     5   166    72    19   175  25.8  0.587   51      1\n",
      "15     7   100     0     0     0  30.0  0.484   32      1\n",
      "16     0   118    84    47   230  45.8  0.551   31      1\n",
      "17     7   107    74     0     0  29.6  0.254   31      1\n",
      "18     1   103    30    38    83  43.3  0.183   33      0\n",
      "19     1   115    70    30    96  34.6  0.529   32      1\n",
      "(768, 9)\n",
      "Explained Variance ratio [ 0.26179749  0.21640127  0.12870373  0.10944113  0.09529305]\n",
      "Explained variance/Eigenvalues [ 2.09437995  1.73121014  1.02962987  0.87552904  0.76234439]\n",
      "Components/eigen vectors [[ 0.1284321   0.39308257  0.36000261  0.43982428  0.43502617  0.45194134\n",
      "   0.27061144  0.19802707]\n",
      " [ 0.59378583  0.17402908  0.18389207 -0.33196534 -0.25078106 -0.1009598\n",
      "  -0.122069    0.62058853]\n",
      " [-0.01308692  0.46792282 -0.53549442 -0.2376738   0.33670893 -0.36186463\n",
      "   0.43318905  0.07524755]\n",
      " [ 0.08069115 -0.40432871  0.05598649  0.03797608 -0.34994376  0.05364595\n",
      "   0.8336801   0.0712006 ]\n",
      " [-0.47560573  0.46632804  0.32795306 -0.48786206 -0.34693481  0.25320376\n",
      "   0.11981049 -0.10928996]]\n",
      "[ 26.18  47.82  60.69  71.63  81.16]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24bdf056198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from sklearn.feature_selection import chi2\n",
    "\n",
    "filename='C:\\\\Users\\\\akoguab\\\\Desktop\\\\R and D\\\\Data science\\\\data set\\\\pimas.csv'\n",
    "names= ['preg', 'plas', 'pres', 'skin', 'test','mass', 'pedi','age','class']\n",
    "\n",
    "dataset=pd.read_csv(filename,names=names)\n",
    "\n",
    "# First 20 rows of your data\n",
    "\n",
    "print(dataset.head(20))\n",
    "\n",
    "# dimensions of your data\n",
    "\n",
    "print(dataset.shape)\n",
    "\n",
    "array=dataset.values\n",
    "X=array[:,0:8]\n",
    "Y=array[:,8]\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "X=scale(X)\n",
    "\n",
    "pca=PCA(n_components=.8)\n",
    "#pca=PCA(n_components=3)\n",
    "fit=pca.fit(X)\n",
    "\n",
    "print(\"Explained Variance ratio\",fit.explained_variance_ratio_)\n",
    "print(\"Explained variance/Eigenvalues\",pca.explained_variance_)\n",
    "print(\"Components/eigen vectors\",pca.components_)\n",
    "\n",
    "var=np.cumsum(np.round(pca.explained_variance_ratio_, decimals=4)*100)\n",
    "\n",
    "print(var)\n",
    "\n",
    "plt.plot(var)\n",
    "\n",
    "plt.show()\n",
    "#print(fit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
